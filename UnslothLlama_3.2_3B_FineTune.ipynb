{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright and Licensing Notice\n",
    "\n",
    "<small>Copyright 2025 H. Umapathithasan, A. Vasantharasan, N. Mehanathan, & N. Kannan\n",
    "This work is licensed under the **Apache License, Version 2.0**.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "**Note:** If you install dependencies using the provided `requirements.txt` file, skip the manual installation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#Get Unsloth (Code used Unsloth 2025.3.10)\n",
    "%pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infuse/anaconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-08 15:27:56.608125: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-08 15:27:56.803672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744140476.871759    1076 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744140476.895568    1076 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 15:27:57.058135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.10: Fast Llama patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4080. Num GPUs = 1. Max memory: 15.992 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 #Max num of input tokens (2048 tokens)\n",
    "dtype = None #None = auto-detect, selects optimal PyTorch data type, used to store model weights/activations\n",
    "load_in_4bit = True # (QLoRA = True) Using 4bit quantization\n",
    "\n",
    "#Select model based on args, can also load LoRA adapters for locally saved unsloth models\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", \n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", #Specify for using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.10 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "#Parmeters for finetuning\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "#LoRA Parameters:\n",
    "    #LoRA rank of decomposition (r)\n",
    "    #Takes original model W, a (m x n matrix), and breaks it down into matrix A(m x r) and matrix B(r x n) matrices\n",
    "    #These smaller matrices are the LoRA adapters that are trained instead of the original weight (W), r is the parameter\n",
    "    #Lower r is faster and more memory-efficient, but less accurate\n",
    "    r = 32, #Use r = 8, 16, 32, 64, 128\n",
    "\n",
    "    #Scaling Factor (lora_alpha) \n",
    "    #LoRA adapters (A and B) are added to the original weight (W) to get the fine-tuned W'\n",
    "    #lora alpha scales the contribution of LoRA adapters to W', similar to learning rate in gradient descent\n",
    "    #Controls how much of the learned features stored in lora adapters contribute to new fine-tuned W'\n",
    "    lora_alpha = 32, #Best to use value equal to r\n",
    "\n",
    "    lora_dropout = 0, # = 0 is optimized, applies dropout to lora adapters, prevents model from relying too much on specific learned features\n",
    "    \n",
    "    #y = Wx + b, where b is bias, W is weight, x is features\n",
    "    bias = \"none\",    # = none is optimized,\n",
    "\n",
    "    #Technique for reducing memory consumption during finetuning\n",
    "    #Instead of storing all intermediate activations on the forward pass of finetuning, it only saves a subset of them\n",
    "    #Computes the rest of the activations on the backward pass, (activations are the computed value that are passed into activation function)\n",
    "    use_gradient_checkpointing = \"unsloth\", #Set True/\"unsloth\" for very long context, \n",
    "                                            #will use less VRAM and fit larger batch sizes, but will increase compute time\n",
    "    #Set seed for reproducible random values\n",
    "    random_state = 3407,\n",
    "    #Rank-Stabilized LoRA\n",
    "    use_rslora = False, #= True will automatically adjust lora_alpha\n",
    "    #LoftQ, applies quanitzation with optimized LoRA initalization\n",
    "    loftq_config = None,\n",
    "    #Select modules to finetune with LoRA\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",   #These are specific projection layers within the \n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],    #transformer model's architecture\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Identifier', 'Type', 'DOI', 'Title', 'Abstract', 'Number of references', 'Study Type', 'Study Population Size', 'Control Group Size', 'Sampling Method'],\n",
      "    num_rows: 4227\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to the CSV files\n",
    "csv_path1 = \"./Dataset/DatasetParams2/good_papers_with_topics_with_params.csv\"  \n",
    "csv_path2 = \"./Dataset/DatasetParams2/bad_papers_with_topics_with_params.csv\" \n",
    "\n",
    "# Load both CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(csv_path1, keep_default_na=False)\n",
    "df2 = pd.read_csv(csv_path2, keep_default_na=False)\n",
    "\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "if \"Number of references\" in combined_df.columns:\n",
    "    combined_df[\"Number of references\"] = pd.to_numeric(combined_df[\"Number of references\"], errors=\"coerce\")\n",
    "\n",
    "# Convert the combined DataFrame to a Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(combined_df)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4227/4227 [00:00<00:00, 49535.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Transform .csv data into conversational template\n",
    "def to_conversational_format(batch):\n",
    "\n",
    "    user_prompts = [\n",
    "        f\"For the given Topic: {identifier}\\nAsnwer if the following academic paper is good or bad\\nTitle: {title}\\nAbstract: {abstract}\\n\"\n",
    "        f\"Number of References: {references}\\nStudy Type: {studyType}\\nStudy Population Size: {popSize}\"\n",
    "        for title, identifier, abstract, references, studyType, popSize in zip(batch[\"Title\"], batch[\"Identifier\"], batch[\"Abstract\"], batch[\"Number of references\"], batch[\"Study Type\"], batch[\"Study Population Size\"])\n",
    "    ]\n",
    "    \n",
    "    #llama response (good/bad)\n",
    "    assistant_responses = batch[\"Type\"]\n",
    "    \n",
    "    #Building dataset as a dictionary in HuggingFace generic format\n",
    "    conversations = [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response} #good/bad\n",
    "        ]\n",
    "        for user_prompt, response in zip(user_prompts, assistant_responses)\n",
    "    ]\n",
    "    \n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "# Apply the transformation\n",
    "dataset = dataset.map(to_conversational_format, batched=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4227/4227 [00:00<00:00, 31738.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 3170\n",
      "Test dataset size: 1057\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "For the given Topic: Ethnicity and clinical outcomes in COVID-19\n",
      "Asnwer if the following academic paper is good or bad\n",
      "Title: Racial and Ethnic Disparities in Population-Level Covid-19 Mortality.\n",
      "Abstract: No abstract found\n",
      "Number of References: 6.0\n",
      "Study Type:  cross-sectional\n",
      "Study Population Size:  not specified<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "bad<|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Transform conversational template into llama template\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "#Initialize tokenizer, specify template to convert dictionary in prev. cell into \n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama-3.1\",\n",
    ")\n",
    "\n",
    "#Function to format the prompts from dict. into the llama chat template\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "#Format the dataset into the chat template\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "#Split dataset into 75% train and 25% test\n",
    "splits = dataset.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "#Access the train and test sets\n",
    "train_dataset_split = splits[\"train\"]\n",
    "test_dataset_split = splits[\"test\"]\n",
    "\n",
    "#Print the size of each split\n",
    "print(f\"Train dataset size: {len(train_dataset_split)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset_split)}\")\n",
    "\n",
    "#Print sample of dataset in llama chat template\n",
    "print(train_dataset_split[2][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Projects/VSCodeWorkspace/StudyScreeningLanguageModel/unsloth_compiled_cache/UnslothSFTTrainer.py:587: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/mnt/c/Projects/VSCodeWorkspace/StudyScreeningLanguageModel/unsloth_compiled_cache/UnslothSFTTrainer.py:601: UserWarning: You passed a `dataset_num_proc` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/mnt/c/Projects/VSCodeWorkspace/StudyScreeningLanguageModel/unsloth_compiled_cache/UnslothSFTTrainer.py:615: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map (num_proc=2): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3170/3170 [00:02<00:00, 1239.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer #Supervised Fine-tuning Trainer from HuggingFace\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq #HF\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "#Specify Trainer Params (Docs: https://huggingface.co/docs/trl/en/sft_trainer)\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset_split,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer), #Batches and preprocesses data\n",
    "    dataset_num_proc = 2, #Num of processes for processing dataset\n",
    "    packing = False, #Packs multiple sequences within max_seq_length (Packs multiple prompts/responses together)\n",
    "    #(Docs: https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments)\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2, #batch size, bigger batch will create smoother training loss curve\n",
    "        gradient_accumulation_steps = 4, \n",
    "        warmup_steps = 5,   #Num of training steps used to slowly increase learning rate from 0 to learning_rate\n",
    "        num_train_epochs = 3, #Num of runs through full dataset (epochs).\n",
    "        # max_steps = 250, #Num of times weights are updated,Total samples visited = batch size * gradient accumulation steps * max steps\n",
    "        learning_rate = 2e-4, #try = 2e-4, 1e-4, 5e-5, 2e-5\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10, #(logging_steps = 1, log training metrics after every 1 step/weight update)\n",
    "        optim = \"adamw_8bit\", #optimizer, carries out gradient descent and adjusts learning rate\n",
    "        weight_decay = 0.01, #Decreases weight during each optimizer step\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", #Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=20): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3170/3170 [00:00<00:00, 6358.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Using Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4080. Max memory = 15.992 GB.\n",
      "2.66 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 3,170 | Num Epochs = 3 | Total steps = 1,188\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 48,627,712/1,889,840,128 (2.57% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1188' max='1188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1188/1188 30:05, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.300500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.183100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.175200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.173400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.154400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810.6626 seconds used for training.\n",
      "30.18 minutes used for training.\n",
      "Peak reserved memory = 3.662 GB.\n",
      "Peak reserved memory for training = 1.002 GB.\n",
      "Peak reserved memory % of max memory = 22.899 %.\n",
      "Peak reserved memory for training % of max memory = 6.266 %.\n",
      "All Metrics: {'train_runtime': 1810.6626, 'train_samples_per_second': 5.252, 'train_steps_per_second': 0.656, 'total_flos': 9.10593802812334e+16, 'train_loss': 0.15609180873341433, 'epoch': 2.998107255520505}\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
    "print(f\"All Metrics: {trainer_stats.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dataset:  1057\n",
      "User Message: For the given Topic: The effect of comorbid pulmonary diseases on the severity of COVID-19 patients\n",
      "Asnwer if the following academic paper is good or bad\n",
      "Title: Association of chronic anticoagulant and antiplatelet use on disease severity in SARS-COV-2 infected patients.\n",
      "Abstract: No abstract found\n",
      "Number of References: 12.0\n",
      "Study Type:  retrospective cohort study\n",
      "Study Population Size:  28076\n",
      "Expected Assistant Response: bad\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of test dataset: \", len(test_dataset_split))\n",
    "# i = 20 #bad sample\n",
    "i = 474 #good sample\n",
    "#print(test_dataset_split[i][\"conversations\"])\n",
    "conversation = test_dataset_split[i][\"conversations\"]\n",
    "\n",
    "# Extract the \"user\" message\n",
    "user_message = next(\n",
    "    (message[\"content\"] for message in conversation if message[\"role\"] == \"user\"), \n",
    "    None\n",
    ")\n",
    "\n",
    "# Extract the \"assistant\" response\n",
    "assistant_response = next(\n",
    "    (message[\"content\"] for message in conversation if message[\"role\"] == \"assistant\"), \n",
    "    None\n",
    ")\n",
    "\n",
    "print(\"User Message:\", user_message)\n",
    "print(\"Expected Assistant Response:\", assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nFor the given Topic: The effect of comorbid pulmonary diseases on the severity of COVID-19 patients\\nAsnwer if the following academic paper is good or bad\\nTitle: Association of chronic anticoagulant and antiplatelet use on disease severity in SARS-COV-2 infected patients.\\nAbstract: No abstract found\\nNumber of References: 12.0\\nStudy Type:  retrospective cohort study\\nStudy Population Size:  28076<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nbad<|eot_id|>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                         temperature = 1.5, min_p = 0.1)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dataset:  1057\n",
      "Unexpected prediction '\\n\\n einer fr√ºhen und einer sp√§ten Phase unterschieden werden k√∂nnen, die eine Therapie unter Differenzierung bed√ºrfen.Ein intensiver Sauerstoffbedarf und eine Abgabe von infekti√∂sen Partikeln sollten die therapeutische Intervall√∂sung der ARI verhind']' from index 489\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "import random \n",
    "\n",
    "print(\"Size of test dataset: \", len(test_dataset_split))\n",
    "# Size is 2499\n",
    "# correct_ans = 0\n",
    "tries = len(test_dataset_split)\n",
    "i = 0\n",
    "\n",
    "# Categorize results as TP, FP, TN, FN\n",
    "tp, fp, tn, fn = 0, 0, 0, 0\n",
    "\n",
    "for index in range(tries):\n",
    "  #print(test_dataset_split[i][\"conversations\"])\n",
    "  # i = random.randint(0,2498)\n",
    "  conversation = test_dataset_split[i][\"conversations\"]\n",
    "\n",
    "  # Extract the user message\n",
    "  user_message = next(\n",
    "      (message[\"content\"] for message in conversation if message[\"role\"] == \"user\"), \n",
    "      None\n",
    "  )\n",
    "\n",
    "  # Extract expected assistant response\n",
    "  assistant_response = next(\n",
    "      (message[\"content\"] for message in conversation if message[\"role\"] == \"assistant\"), \n",
    "      None\n",
    "  )\n",
    "  i+=1\n",
    "\n",
    "  #   print(\"User Message:\", user_message)\n",
    "  #   print(\"Expected Assistant Response:\", assistant_response)\n",
    "\n",
    "  tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    "  )\n",
    "  FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "  messages = [\n",
    "      {\"role\": \"user\", \"content\": user_message},\n",
    "  ]\n",
    "  inputs = tokenizer.apply_chat_template(\n",
    "      messages,\n",
    "      tokenize = True,\n",
    "      add_generation_prompt = True, # Must add for generation\n",
    "      return_tensors = \"pt\",\n",
    "  ).to(\"cuda\")\n",
    "\n",
    "  outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                          temperature = 1.0, min_p = 0.1)   #Test temp=1.0, temp=1.5\n",
    "  model_response = str(tokenizer.batch_decode(outputs))\n",
    "  ans = model_response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1].split(\"<|eot_id|>\")[0].strip()\n",
    "  \n",
    "  \n",
    "  if \"good\" in assistant_response:\n",
    "\n",
    "    if \"good\" in ans:\n",
    "      tp += 1\n",
    "    elif \"bad\" in ans:\n",
    "      fn += 1\n",
    "    else:\n",
    "      print(f\"Unexpected prediction '{ans}' from index {i}\")\n",
    "  elif \"bad\" in assistant_response:\n",
    "\n",
    "    if \"bad\" in ans:\n",
    "      tn += 1\n",
    "    elif \"good\" in ans:\n",
    "      fp += 1\n",
    "    else:\n",
    "      print(f\"Unexpected prediction '{ans}' from index {i}\")\n",
    "  else:\n",
    "    print(f\"Unexpected target prediction '{assistant_response}' from index {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=194, FP=54, TN=770, FN=38\n",
      "Number of correct answers:  964\n",
      "Number of wrong answers:  92\n",
      "# of tests:  1057\n",
      "\n",
      "Accuracy = 0.9128787878787878\n",
      "Recall = 0.8362068965517241\n",
      "Precision = 0.782258064516129\n"
     ]
    }
   ],
   "source": [
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "print(\"Number of correct answers: \", tp + tn)\n",
    "print(\"Number of wrong answers: \", fp + fn)\n",
    "print(\"# of tests: \", tries)\n",
    "\n",
    "print(f\"\\nAccuracy = {accuracy}\\nRecall = {recall}\\nPrecision = {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1076/1584894471.py:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + ['Bad', 'Good'])\n",
      "/tmp/ipykernel_1076/1584894471.py:15: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + ['Bad', 'Good'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Construct the confusion matrix\n",
    "confusion_matrix = np.array([[tn, fp],\n",
    "                             [fn, tp]])\n",
    "\n",
    "#Plotting\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(confusion_matrix, cmap='Blues')\n",
    "plt.colorbar(cax)\n",
    "\n",
    "#Add labels\n",
    "ax.set_xticklabels([''] + ['Bad', 'Good'])\n",
    "ax.set_yticklabels([''] + ['Bad', 'Good'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "\n",
    "#Annotate each cell with its value\n",
    "for (i, j), val in np.ndenumerate(confusion_matrix):\n",
    "    ax.text(j, i, f'{val}', ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama3.2_3B_fullParamDataset_3epoch/tokenizer_config.json',\n",
       " 'llama3.2_3B_fullParamDataset_3epoch/special_tokens_map.json',\n",
       " 'llama3.2_3B_fullParamDataset_3epoch/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"llama3.2_3B_fullParamDataset_3epoch\") # Local saving\n",
    "tokenizer.save_pretrained(\"llama3.2_3B_fullParamDataset_3epoch\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
      "This might take 5 minutes...\n",
      "Done.\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\n",
      "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
      "This might take 5 minutes...\n",
      "Done.\n",
      "Unsloth: Saving 4bit Bitsandbytes model. Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [12:27<00:00, 747.43s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged_4bit model to https://huggingface.co/1nfuse/llama3.2-3B_SLR_FTmodel-4bit-3epoch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# API Key Handle\n",
    "try:\n",
    "  from dotenv import load_dotenv\n",
    "  \n",
    "  load_dotenv('key.env')\n",
    "  key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed\")\n",
    "    key = None\n",
    "except OSError:\n",
    "    print(\"key.env file not found\")\n",
    "    key = None\n",
    "\n",
    "if key is None:\n",
    "    print(\"No API key found\\nIf you are pushing to a repo set it in key.env file.\")\n",
    "\n",
    "# Merge to 16bit\n",
    "# if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "# if True: model.push_to_hub_merged(\"username/model_name\", tokenizer, save_method = \"merged_16bit\", token = key)\n",
    "\n",
    "# # Merge to 4bit\n",
    "# Find our model on HuggingFace at 1nfuse/llama3.2-3B_SLR_FTmodel-4bit-3epoch\n",
    "# if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\",)\n",
    "# if True: model.push_to_hub_merged(\"username/model_name\", tokenizer, save_method = \"merged_4bit_forced\", token = key)\n",
    "\n",
    "# # Save to q4_k_m GGUF\n",
    "# Find our model on HuggingFace at 1nfuse/llama3.2-3B_SLR_FTmodel-q4km-3epoch\n",
    "# if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "# if True: model.push_to_hub_gguf(\"username/model_name\", tokenizer, quantization_method = \"q4_k_m\", token = key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
